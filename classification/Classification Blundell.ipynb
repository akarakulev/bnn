{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from local_logger import Logger\n",
    "from blundell import Net, Loss\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU for computation if possible\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "def get_mnist(batch_size):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "        transform=transform), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, download=True,\n",
    "        transform=transform), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,60,70,80], gamma=0.2)\n",
    "\n",
    "fmt = {'tr_los': '3.1e', 'te_loss': '3.1e', 'sp_0': '.3f', 'sp_1': '.3f', 'lr': '3.1e', 'kl': '.2f'}\n",
    "logger = Logger('sparse_vd', fmt=fmt)\n",
    "\n",
    "train_loader, test_loader = get_mnist(batch_size=100)\n",
    "loss_function = Loss(model, len(train_loader.dataset)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch       lr    tr_los    tr_acc    te_loss    te_acc    kl_reg_0    kl_reg_1    kl_reg_2    time\n",
      "-------  -------  --------  --------  ---------  --------  ----------  ----------  ----------  ------\n",
      "      1  1.0e-03  -4.0e+02      90.9   -5.3e+02      95.9    537418.8     67082.5      2092.9    12.9\n",
      "      2  1.0e-03  -5.4e+02      96.5   -5.5e+02      96.9    539422.7     68432.7      2154.2    12.5\n",
      "      3  1.0e-03  -5.6e+02      97.5   -5.6e+02      97.4    540277.4     68744.6      2218.6    12.5\n",
      "      4  1.0e-03  -5.7e+02      98.0   -5.7e+02      97.6    540599.0     68796.2      2228.5    12.5\n",
      "      5  1.0e-03  -5.8e+02      98.3   -5.7e+02      97.5    541003.4     68899.7      2246.5    12.6\n",
      "      6  1.0e-03  -5.9e+02      98.6   -5.7e+02      97.7    541119.9     68978.2      2263.9    12.1\n",
      "      7  1.0e-03  -5.9e+02      98.7   -5.6e+02      97.7    541284.3     69139.3      2280.7    12.1\n",
      "      8  1.0e-03  -5.9e+02      98.9   -5.7e+02      97.8    541377.7     69169.9      2280.8    12.0\n",
      "      9  1.0e-03  -6.0e+02      99.1   -5.7e+02      97.9    541494.6     69111.0      2295.0    11.9\n",
      "     10  1.0e-03  -6.0e+02      99.2   -5.7e+02      97.9    541993.1     69352.0      2303.3    12.0\n",
      "     11  1.0e-03  -6.0e+02      99.2   -5.6e+02      97.7    541277.1     69225.6      2301.4    12.0\n",
      "     12  1.0e-03  -6.0e+02      99.3   -5.6e+02      98.0    542229.5     69385.4      2301.1    12.1\n",
      "     13  1.0e-03  -6.0e+02      99.3   -5.5e+02      97.5    542083.6     69375.0      2298.3    12.0\n",
      "     14  1.0e-03  -6.0e+02      99.4   -5.6e+02      98.0    542156.6     69463.5      2291.8    12.2\n",
      "     15  1.0e-03  -6.0e+02      99.4   -5.6e+02      97.9    542501.9     69563.8      2302.7    12.2\n",
      "     16  1.0e-03  -6.0e+02      99.4   -5.6e+02      98.1    542482.1     69568.7      2297.6    12.6\n",
      "     17  1.0e-03  -6.1e+02      99.5   -5.5e+02      97.8    542572.6     69683.8      2309.7   189.1\n",
      "     18  1.0e-03  -6.1e+02      99.6   -5.4e+02      97.8    542914.8     69774.4      2312.5    13.4\n",
      "     19  1.0e-03  -6.0e+02      99.4   -5.5e+02      97.6    542541.8     69670.7      2303.0    12.4\n",
      "     20  1.0e-03  -6.1e+02      99.6   -5.5e+02      97.8    543046.4     69810.0      2312.4    12.3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m train_loss, train_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m      8\u001b[0m logger\u001b[39m.\u001b[39madd_scalar(epoch, \u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m, scheduler\u001b[39m.\u001b[39mget_last_lr()[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m     10\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     11\u001b[0m     target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m~/Documents/Deep-Bayes/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/Documents/Deep-Bayes/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Deep-Bayes/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:58\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     55\u001b[0m cmd \u001b[39m=\u001b[39m spawn\u001b[39m.\u001b[39mget_command_line(tracker_fd\u001b[39m=\u001b[39mtracker_fd,\n\u001b[1;32m     56\u001b[0m                              pipe_handle\u001b[39m=\u001b[39mchild_r)\n\u001b[1;32m     57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds\u001b[39m.\u001b[39mextend([child_r, child_w])\n\u001b[0;32m---> 58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39;49mspawnv_passfds(spawn\u001b[39m.\u001b[39;49mget_executable(),\n\u001b[1;32m     59\u001b[0m                                cmd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fds)\n\u001b[1;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/util.py:452\u001b[0m, in \u001b[0;36mspawnv_passfds\u001b[0;34m(path, args, passfds)\u001b[0m\n\u001b[1;32m    450\u001b[0m errpipe_read, errpipe_write \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpipe()\n\u001b[1;32m    451\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     \u001b[39mreturn\u001b[39;00m _posixsubprocess\u001b[39m.\u001b[39;49mfork_exec(\n\u001b[1;32m    453\u001b[0m         args, [os\u001b[39m.\u001b[39;49mfsencode(path)], \u001b[39mTrue\u001b[39;49;00m, passfds, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    454\u001b[0m         \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, errpipe_read, errpipe_write,\n\u001b[1;32m    455\u001b[0m         \u001b[39mFalse\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    456\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     os\u001b[39m.\u001b[39mclose(errpipe_read)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MNIST_INPUT_SHAPE = 28 * 28\n",
    "epochs = 40\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    logger.add_scalar(epoch, 'lr', scheduler.get_last_lr()[0])\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        data = data.view(-1, MNIST_INPUT_SHAPE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss\n",
    "        pred = output.data.max(1)[1]\n",
    "        train_acc += np.sum(pred.cpu().numpy() == target.cpu().data.numpy())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    logger.add_scalar(epoch, 'tr_los', train_loss / len(train_loader.dataset))\n",
    "    logger.add_scalar(epoch, 'tr_acc', train_acc / len(train_loader.dataset) * 100)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        data = data.view(-1, MNIST_INPUT_SHAPE)\n",
    "        output = model(data)\n",
    "        test_loss += float(loss_function(output, target)) #, kl_weight))\n",
    "        pred = output.data.max(1)[1]\n",
    "        test_acc += np.sum(pred.cpu().numpy() == target.cpu().data.numpy())\n",
    "\n",
    "    logger.add_scalar(epoch, 'te_loss', test_loss / len(test_loader.dataset))\n",
    "    logger.add_scalar(epoch, 'te_acc', test_acc / len(test_loader.dataset) * 100)\n",
    "\n",
    "    for i, c in enumerate(model.children()):\n",
    "        if hasattr(c, 'kl_reg'):\n",
    "            logger.add_scalar(epoch, 'kl_reg_%s' % i, -c.kl_reg())\n",
    "\n",
    "    end = time.time()\n",
    "    logger.add_scalar(epoch, 'time', end - start)\n",
    "\n",
    "    logger.iter_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
